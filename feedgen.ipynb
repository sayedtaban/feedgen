{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC052A0fUket"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz55Y6LaUrtU"
      },
      "source": [
        "<img align=\"left\" width=\"150\" src=\"https://services.google.com/fh/files/misc/feedgen_logo.png\" alt=\"feedgen_logo\" />\n",
        "\n",
        "# FeedGen\n",
        "**Optimse Google Shopping feeds with Generative AI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv9BOMoAUw79"
      },
      "source": [
        "**Disclaimer: This is not an official Google product.**\n",
        "\n",
        "**FeedGen** is an open-source tool that uses Google Cloud's state-of-the-art Large Language Models (LLMs) in Vertex AI and novel prompt-tuning to generate optimised Google Shopping ad titles and descriptions. It helps merchants and advertisers surface and fix quality issues in their Shopping feeds using Generative AI in a configurable, user-friendly and privacy-preserving manner.\n",
        "\n",
        "More information available at [github.com/google/feedgen](https://github.com/google/feedgen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40xdBGbjFoeG"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9woz0nXeVls9"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate your user for this colab session\n",
        "import logging\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "logging.getLogger().setLevel(logging.INFO) # Change to logging.DEBUG for more fine-grained logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9yUo6WTAV2VF"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install tensorflow_text google-cloud-aiplatform==1.25.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b6Mkwphg80V"
      },
      "source": [
        "###‚ùó <span style=\"font-size: large\">Do not forget to click the \"Restart runtime\" button above (if prompted), and then re-run the authentication cell</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-9INPTwcd-W"
      },
      "source": [
        "## Input\n",
        "\n",
        "Choose how you want to provide the input data (Google Sheets or Google Cloud BigQuery) and run the associated cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nhOgiE9mKTT2"
      },
      "outputs": [],
      "source": [
        "from gspread.utils import is_scalar\n",
        "#@title Common configurable parameters { run: 'auto' }\n",
        "# #@markdown Select the desired input data source then run the associated cells below:\n",
        "# desired_data_source = \"Google Sheets\" #@param [\"Google Sheets\", \"Google Cloud BigQuery\"]\n",
        "# is_sheets_data_source = desired_data_source == 'Google Sheets'\n",
        "# is_bigquery_data_source = desired_data_source == 'Google Cloud BigQuery'\n",
        "\n",
        "from typing import Sequence\n",
        "\n",
        "def convert_comma_seperated_str_to_list(\n",
        "    comma_separated_string: str) -> Sequence[str]:\n",
        "  if ',' in comma_separated_string:\n",
        "    return comma_separated_string.replace(', ', ',').split(',')\n",
        "  return [] if not comma_separated_string else [comma_separated_string]\n",
        "\n",
        "#@markdown Choose the desired input data source:\n",
        "FEED_INPUT_DATA_SOURCE = \"Google Sheets\" #@param [\"Google Sheets\", \"Google Cloud BigQuery\"]\n",
        "IS_SHEETS_DATA_SOURCE = FEED_INPUT_DATA_SOURCE == 'Google Sheets'\n",
        "IS_BIGQUERY_DATA_SOURCE = FEED_INPUT_DATA_SOURCE == 'Google Cloud BigQuery'\n",
        "\n",
        "#@markdown Enter the column representing the ID of each feed item in your input:\n",
        "FEED_ITEM_ID = \"Item ID\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the column representing your brand name in the input:\n",
        "FEED_BRAND_NAME = \"Brand\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the column containing the current title of each feed item in your input:\n",
        "FEED_ITEM_TITLE = \"Title\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the column containing the current description of each feed item in your input:\n",
        "FEED_ITEM_DESCRIPTION = \"Description\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter comma-separated column names representing the main feed item features that **must** be present in the generated titles and descriptions (existing titles and descriptions missing any one of those features will be flagged as invalid):\n",
        "FEED_ITEM_MAIN_FEATURES = \"Brand, Size, Color\" #@param {type:\"string\"}\n",
        "FEED_ITEM_MAIN_FEATURES = convert_comma_seperated_str_to_list(FEED_ITEM_MAIN_FEATURES)\n",
        "\n",
        "#@markdown Enter which features from `FEED_ITEM_MAIN_FEATURES` need to be matched *exactly* as-is (e.g. the brand name):\n",
        "FEED_ITEM_EXACT_MATCH_FEATURES = \"Brand\" #@param {type:\"string\"}\n",
        "FEED_ITEM_EXACT_MATCH_FEATURES = convert_comma_seperated_str_to_list(FEED_ITEM_EXACT_MATCH_FEATURES)\n",
        "\n",
        "#@markdown Enter a [Cosine Similarity](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity) threshold value for matching features in the titles and descriptions *semantically*:\n",
        "FEED_ITEM_FEATURE_SIMILARITY_THRESHOLD = 0.6 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "#@markdown Enter the minimum valid length for feed item descriptions (existing descriptions with lengths below that threshold will be flagged as invalid):\n",
        "FEED_ITEM_DESCRIPTION_LENGTH_THRESHOLD = 500 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Enter the name of a column that contains a metric you would like to use for sorting the input feed items (e.g. *Clicks*).\n",
        "#@markdown Low quality items (e.g. with the least amount of 'Clicks') will be sorted and processed first.\n",
        "#@markdown <br>Leave empty to use the default sorting (which sorts the lowest quality feed items as identified by FeedGen's validation rules first):\n",
        "FEED_SORT_METRIC = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Non-user defined parameters\n",
        "FEED_OUTPUT_ITEM_ID = 'Item ID' # Fixed for the output regardless of `FEED_ITEM_ID`\n",
        "FEED_OUTPUT_TITLE = 'Original Title' # Fixed for the output regardless of `FEED_ITEM_TITLE`\n",
        "FEED_OUTPUT_DESCRIPTION = 'Original Description' # Fixed for the output regardless of `FEED_ITEM_DESCRIPTION`\n",
        "FEED_OUTPUT_GENERATED_TITLE = 'Generated Title'\n",
        "FEED_OUTPUT_GENERATED_TITLE_STATUS = 'Generated Title Status'\n",
        "FEED_OUTPUT_GENERATED_TITLE_SIMILARITY_SCORE = 'Generated Title Features Similarity Score'\n",
        "FEED_OUTPUT_GENERATED_TITLE_VARIANTS = 'Generated Title Variants'\n",
        "FEED_OUTPUT_GENERATED_TITLE_MODEL_PARAMS = 'Generated Title Model Parameters'\n",
        "FEED_OUTPUT_MISSING_FEATURES_IN_TITLE = 'Missing Features in Original Title'\n",
        "FEED_OUTPUT_MISSING_FEATURES_TITLE_SIMILARITY_SCORE = 'Original Title Features Similarity Score'\n",
        "FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_TITLE = 'Missing Features in Generated Title'\n",
        "FEED_OUTPUT_MISSING_FEATURES_IN_DESCRIPTION = 'Missing Features in Original Description'\n",
        "FEED_OUTPUT_MISSING_FEATURES_DESCRIPTION_SIMILARITY_SCORE = 'Original Description Features Similarity Score'\n",
        "FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_DESCRIPTION = 'Missing Features in Generated Description'\n",
        "FEED_OUTPUT_GENERATED_DESCRIPTION = 'Generated Description'\n",
        "FEED_OUTPUT_GENERATED_DESCRIPTION_STATUS = 'Generated Description Status'\n",
        "FEED_OUTPUT_GENERATED_DESCRIPTION_SIMILARITY_SCORE = 'Generated Description Features Similarity Score'\n",
        "FEED_OUTPUT_GENERATED_DESCRIPTION_VARIANTS = 'Generated Description Variants'\n",
        "FEED_OUTPUT_GENERATED_DESCRIPTION_MODEL_PARAMS = 'Generated Description Model Parameters'\n",
        "\n",
        "FEED_OUTPUT_STATUS_NEEDS_APROVAL = 'Needs Approval'\n",
        "FEED_OUTPUT_STATUS_PRE_APPROVED = 'Pre-Approved'\n",
        "\n",
        "FEED_SUMMARY_LOW_QUALITY_TITLES = 'Low Quality Original Titles'\n",
        "FEED_SUMMARY_LOW_QUALITY_DESCRIPTIONS = 'Low Quality Original Descriptions'\n",
        "FEED_SUMMARY_MISSING_DESCRIPTIONS = 'Missing Original Descriptions'\n",
        "FEED_SUMMARY_SHORT_DESCRIPTIONS = f'Original Descriptions < {FEED_ITEM_DESCRIPTION_LENGTH_THRESHOLD} Characters'\n",
        "\n",
        "# Validation rules\n",
        "if not FEED_ITEM_MAIN_FEATURES:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least ONE main feature is specified '\n",
        "      'in \"FEED_ITEM_MAIN_FEATURES\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF1rUy2hqp8A"
      },
      "source": [
        "### Google Sheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nUyN1wRmaMCw"
      },
      "outputs": [],
      "source": [
        "#@title Configurable parameters { run: 'auto' }\n",
        "\n",
        "#@markdown Enter your spreadsheet ID:\n",
        "SPREADSHEET_ID = \"sheet-id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the main worksheet name which contains the input feed data:\n",
        "INPUT_SHEET_NAME = \"Input Feed\" #@param {type:\"string\"}\n",
        "\n",
        "# Validation rules\n",
        "if IS_SHEETS_DATA_SOURCE and (not SPREADSHEET_ID or not INPUT_SHEET_NAME):\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"SPREADSHEET_ID\" AND \"INPUT_SHEET_NAME\" '\n",
        "      'are provided.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nUTcrhJNakGu"
      },
      "outputs": [],
      "source": [
        "#@title Fetch data from the input spreadsheet\n",
        "#@markdown The first row in each worksheet will be considered the **column headers** row.\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "input_feed_data = None\n",
        "\n",
        "if IS_SHEETS_DATA_SOURCE:\n",
        "  creds, _ = default()\n",
        "  sheets_client = gspread.authorize(creds)\n",
        "  spreadsheet = sheets_client.open_by_key(SPREADSHEET_ID)\n",
        "\n",
        "  input_feed_values = spreadsheet.worksheet(INPUT_SHEET_NAME).get_all_values()\n",
        "  input_feed_data = pd.DataFrame(\n",
        "      input_feed_values[1:], columns=input_feed_values[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CfxrLUjxiQ"
      },
      "source": [
        "### Google Cloud BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z9uBlfJ5j4Ga"
      },
      "outputs": [],
      "source": [
        "#@title Configurable parameters { run: 'auto' }\n",
        "\n",
        "#@markdown Enter the Google Cloud Project ID associated with your BigQuery data:\n",
        "GCP_BIGQUERY_PROJECT_ID = \"gcp-project-id-goes-here\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the SQL query you would like to execute to pull data from BigQuery\n",
        "#@markdown (*Expand this cell to view a sample query for the [Google Merchant Center Data Transfer](https://cloud.google.com/bigquery/docs/merchant-center-transfer)*):\n",
        "BQ_INPUT_QUERY = \"SELECT * FROM `dataset.table` WHERE column = \\\"value\\\" ORDER BY column\" #@param {type:\"string\"}\n",
        "\n",
        "# Google Ads BigQuery Data Transfer sample query\n",
        "gcp_mc_transfer_dataset_name = 'merchant_center' # Dataset where the transfer has been stored\n",
        "gcp_mc_transfer_merchant_id = '0' # Enter the <merchant_id> if you are using an individual Merchant, or the <aggregator_id> if you are using an MCA account.\n",
        "bg_input_query_sample = f\"\"\"\n",
        "SELECT\n",
        "  P.product_id AS `Item ID`,\n",
        "  P.brand AS `Brand`,\n",
        "  P.title AS `Title`,\n",
        "  P.description AS `Description`,\n",
        "  P.color AS `Color`,\n",
        "  P.material AS `Material`,\n",
        "  P.link AS `Landing Page`,\n",
        "  P.image_link AS `Image Link`,\n",
        "  P.sale_price.value AS `Price`,\n",
        "FROM\n",
        "  `{GCP_BIGQUERY_PROJECT_ID}.{gcp_mc_transfer_dataset_name}.Product_{gcp_mc_transfer_merchant_id}` AS P\n",
        "ORDER BY `Item ID`;\n",
        "\"\"\"\n",
        "\n",
        "# Validation rules\n",
        "if IS_BIGQUERY_DATA_SOURCE and (\n",
        "    not GCP_BIGQUERY_PROJECT_ID or not BQ_INPUT_QUERY):\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"GCP_BIGQUERY_PROJECT_ID\" AND \"BQ_INPUT_QUERY\" '\n",
        "      'are provided.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sZTYpduPq8o5"
      },
      "outputs": [],
      "source": [
        "#@title Fetch data from GCP BigQuery\n",
        "%%bigquery fetched_feed --project $GCP_BIGQUERY_PROJECT_ID\n",
        "$BQ_INPUT_QUERY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nLW-OZIWNHAX"
      },
      "outputs": [],
      "source": [
        "#@title Store the fetched data into a Pandas DataFrame\n",
        "if IS_BIGQUERY_DATA_SOURCE:\n",
        "  input_feed_data = fetched_feed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNhGd8iExNM9"
      },
      "source": [
        "## Preprocessing and Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8iTgnqSRzwe5"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "import re\n",
        "from typing import Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text # do not remove unused import as it's required in runtime\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "USE_MODEL = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
        "\n",
        "\n",
        "def remove_spaces(text: str) -> str:\n",
        "  return text.replace(' ', '')\n",
        "\n",
        "def get_missing_semantic_match_features(\n",
        "    ground_truth_features: Mapping[str, str],\n",
        "    target_text: str,\n",
        "    model: tf.Module = USE_MODEL) -> Mapping[str, float]:\n",
        "  feature_keys = list(ground_truth_features.keys())\n",
        "  feature_values = list(ground_truth_features.values())\n",
        "  target_text_words = (\n",
        "      tf.keras.preprocessing.text.text_to_word_sequence(target_text))\n",
        "  logging.debug('target_text_words: %r', target_text_words)\n",
        "\n",
        "  embeddings_features = model(feature_values)\n",
        "  embeddings_target = model(target_text_words)\n",
        "  similarity = tf.reduce_sum(\n",
        "      embeddings_features[:, tf.newaxis] * embeddings_target, axis=-1)\n",
        "  similarity = tf.math.divide(similarity, tf.norm(\n",
        "      embeddings_features[:, tf.newaxis], axis=-1) * tf.norm(\n",
        "          embeddings_target, axis=-1))\n",
        "\n",
        "  indices = tf.math.argmax(similarity, axis=1).numpy()\n",
        "  max_similarity = tf.math.reduce_max(similarity, axis=1).numpy()\n",
        "\n",
        "  feature_cosine_similarity_words_and_score = {}\n",
        "\n",
        "  for i in range(len(feature_keys)):\n",
        "    feature_cosine_similarity_words_and_score[feature_keys[i]] = (\n",
        "        feature_values[i], target_text_words[indices[i]], max_similarity[i])\n",
        "\n",
        "  logging.debug(\n",
        "      'feature_cosine_similarity_words_and_score: %r',\n",
        "      feature_cosine_similarity_words_and_score)\n",
        "\n",
        "  return {\n",
        "      key: cosine_similarity for key, (original, _, cosine_similarity) in feature_cosine_similarity_words_and_score.items()\n",
        "      if cosine_similarity < FEED_ITEM_FEATURE_SIMILARITY_THRESHOLD}\n",
        "\n",
        "def get_missing_features_in_text(\n",
        "    item_row: pd.Series,\n",
        "    text: str,\n",
        "    main_features: Sequence[str] = FEED_ITEM_MAIN_FEATURES) -> Tuple[str, str]:\n",
        "  exact_match_features = {}\n",
        "  semantic_match_features = {}\n",
        "  text = text.lower()\n",
        "\n",
        "  for feature in main_features:\n",
        "    feature_value = str(item_row[feature]).lower()\n",
        "    if feature in FEED_ITEM_EXACT_MATCH_FEATURES:\n",
        "      exact_match_features[feature] = feature_value\n",
        "    else:\n",
        "      semantic_match_features[feature] = feature_value\n",
        "\n",
        "  logging.debug('exact_match_features: %r', exact_match_features)\n",
        "  logging.debug('semantic_match_features: %r', semantic_match_features)\n",
        "\n",
        "  missing_exact_match_features = [\n",
        "      feature for feature, feature_value in exact_match_features.items()\n",
        "      if len(feature_value) == 0 or (\n",
        "          feature_value not in text and remove_spaces(feature_value) not in remove_spaces(text))]\n",
        "  logging.debug('Missing exact match features: %r', missing_exact_match_features)\n",
        "\n",
        "  missing_semantic_match_features = get_missing_semantic_match_features(\n",
        "      ground_truth_features=semantic_match_features,\n",
        "      target_text=text)\n",
        "  logging.debug(\n",
        "      'Missing semantic match features: %r', missing_semantic_match_features)\n",
        "\n",
        "  missing_feature_keys = (\n",
        "      missing_exact_match_features + list(missing_semantic_match_features.keys()))\n",
        "  missing_feature_similarity_scores = (\n",
        "      [0 for i in range(len(missing_exact_match_features))] + list(missing_semantic_match_features.values()))\n",
        "\n",
        "  logging.debug(\n",
        "      'missing_feature_keys: %r', missing_feature_keys)\n",
        "  logging.debug(\n",
        "      'missing_feature_similarity_scores: %r', missing_feature_similarity_scores)\n",
        "\n",
        "  return (\n",
        "      ', '.join(missing_feature_keys),\n",
        "      ', '.join([f'{value:.2f}' for value in missing_feature_similarity_scores]))\n",
        "\n",
        "def calculate_feature_missing_count(\n",
        "    item_row: pd.Series,\n",
        "    item_key: str,\n",
        "    feature: str) -> int:\n",
        "  feature_value = str(item_row[feature]).lower()\n",
        "  text = str(item_row[item_key]).lower()\n",
        "\n",
        "  if feature in FEED_ITEM_EXACT_MATCH_FEATURES:\n",
        "    return 1 if len(feature_value) == 0 or (\n",
        "        feature_value not in text and remove_spaces(feature_value) not in remove_spaces(text)) else 0\n",
        "  else:\n",
        "    res = get_missing_semantic_match_features({feature: feature_value}, text)\n",
        "    return 1 if feature in res else 0\n",
        "\n",
        "def calculate_feature_missing_counts(\n",
        "    item_key: str,\n",
        "    main_features: Sequence[str] = FEED_ITEM_MAIN_FEATURES) -> Tuple[Mapping[str, int], Sequence[str]]:\n",
        "  feature_missing_counts_dict = {}\n",
        "  features_to_remove = []\n",
        "\n",
        "  for feature in main_features:\n",
        "    logging.info(\n",
        "        'Evaluating input for the main feature: \"%s\" and column: \"%s\"...',\n",
        "        feature,\n",
        "        item_key)\n",
        "    feature_missing = pd.DataFrame()\n",
        "    feature_missing[feature] = input_feed_data.progress_apply(lambda row: calculate_feature_missing_count(row, item_key, feature), axis=1)\n",
        "    count_feature_missing = sum(feature_missing[feature])\n",
        "\n",
        "    if count_feature_missing == len(input_feed_data):\n",
        "      logging.warning(\n",
        "          'WARNING! The feature \"%s\" is missing in all values of the '\n",
        "          'column \"%s\", yet is defined in \"FEED_ITEM_MAIN_FEATURES\". '\n",
        "          'This feature will be removed from the set of main features.',\n",
        "          feature, item_key)\n",
        "      features_to_remove.append(feature)\n",
        "    else:\n",
        "      feature_missing_counts_dict[feature] = count_feature_missing\n",
        "\n",
        "  main_features = [\n",
        "      feature for feature in main_features\n",
        "      if feature not in features_to_remove]\n",
        "  if not main_features:\n",
        "    raise ValueError(\n",
        "      'Invalid input! All \"FEED_ITEM_MAIN_FEATURES\" have been removed as '\n",
        "      'they do not exist in the provided input. '\n",
        "      'Please correct your input data and try again.')\n",
        "  return feature_missing_counts_dict, main_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WOWTeXSfcKaO"
      },
      "outputs": [],
      "source": [
        "#@title Calculate validation metrics for the input data\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "features_missing_in_titles, main_features = calculate_feature_missing_counts(FEED_ITEM_TITLE)\n",
        "features_missing_in_descriptions, main_features = calculate_feature_missing_counts(FEED_ITEM_DESCRIPTION, main_features)\n",
        "\n",
        "logging.info(\n",
        "    'Identifying missing exact and semantic features for the column: \"%s\"...',\n",
        "    FEED_ITEM_TITLE)\n",
        "input_feed_data[[\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_TITLE,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_TITLE_SIMILARITY_SCORE,\n",
        "]] = input_feed_data.progress_apply(\n",
        "    lambda row: get_missing_features_in_text(row, row[FEED_ITEM_TITLE], main_features),\n",
        "    axis='columns',\n",
        "    result_type='expand')\n",
        "\n",
        "logging.info(\n",
        "    'Identifying missing exact and semantic features for the column: \"%s\"...',\n",
        "    FEED_ITEM_DESCRIPTION)\n",
        "input_feed_data[[\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_DESCRIPTION,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_DESCRIPTION_SIMILARITY_SCORE,\n",
        "]] = input_feed_data.progress_apply(\n",
        "    lambda row: get_missing_features_in_text(row, row[FEED_ITEM_DESCRIPTION], main_features),\n",
        "    axis='columns',\n",
        "    result_type='expand')\n",
        "\n",
        "logging.info('Creating an overview of quality issues in the input feed...')\n",
        "total_input_rows = len(input_feed_data)\n",
        "input_feed_summary = pd.DataFrame()\n",
        "input_feed_summary[FEED_SUMMARY_LOW_QUALITY_TITLES] = [round(len(\n",
        "    input_feed_data[input_feed_data[FEED_OUTPUT_MISSING_FEATURES_IN_TITLE].str.len() > 0]\n",
        ") / total_input_rows * 100, 2)]\n",
        "input_feed_summary[FEED_SUMMARY_LOW_QUALITY_DESCRIPTIONS] = [round(len(\n",
        "    input_feed_data[input_feed_data[FEED_OUTPUT_MISSING_FEATURES_IN_DESCRIPTION].str.len() > 0]\n",
        ") / total_input_rows * 100, 2)]\n",
        "input_feed_summary[FEED_SUMMARY_MISSING_DESCRIPTIONS] = [round(len(\n",
        "    input_feed_data[input_feed_data[FEED_ITEM_DESCRIPTION] == input_feed_data[FEED_ITEM_TITLE]]\n",
        ") / total_input_rows * 100, 2)]\n",
        "input_feed_summary[FEED_SUMMARY_SHORT_DESCRIPTIONS] = [round(len(\n",
        "    input_feed_data[input_feed_data[FEED_ITEM_DESCRIPTION].str.len() < FEED_ITEM_DESCRIPTION_LENGTH_THRESHOLD]\n",
        ") / total_input_rows * 100, 2)]\n",
        "\n",
        "if FEED_SORT_METRIC and FEED_SORT_METRIC in input_feed_data.columns:\n",
        "  input_feed_data.sort_values(by=FEED_SORT_METRIC, inplace=True)\n",
        "else:\n",
        "  input_feed_data['missing_features_count'] = input_feed_data[\n",
        "      FEED_OUTPUT_MISSING_FEATURES_IN_TITLE].str.len() + input_feed_data[\n",
        "          FEED_OUTPUT_MISSING_FEATURES_IN_DESCRIPTION].str.len()\n",
        "  input_feed_data.sort_values(\n",
        "        by='missing_features_count', ascending=False, inplace=True)\n",
        "  input_feed_data.drop(columns='missing_features_count', inplace=True)\n",
        "\n",
        "FEED_ITEM_MAIN_FEATURES = main_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_svoHqnobzfv"
      },
      "outputs": [],
      "source": [
        "#@title Preview the fetched data\n",
        "input_feed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-RCFAGAb08A"
      },
      "outputs": [],
      "source": [
        "#@title Display an overview of the quality issues in the input feed\n",
        "input_feed_summary.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt9Qbpl4IMTs"
      },
      "source": [
        "## Inference\n",
        "\n",
        "FeedGen supports the use of both foundational models from Google Cloud as well as models that have been fine-tuned on proprietary data, and applies prompt-tuning to generate titles and descriptions respectively. Refer to this [guide](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview) for an overview of prompt design, and this [guide](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) for how to fine-tune and deploy custom models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LJ0BSzOh2W6T"
      },
      "outputs": [],
      "source": [
        "#@title Configurable parameters { run: 'auto' }\n",
        "\n",
        "#@markdown Enter the language in which you would like to generate titles and descriptions:\n",
        "GENERATION_LANGUAGE = \"English\" #@param [\"English\", \"French\", \"German\"] {allow-input: true}\n",
        "\n",
        "#@markdown <hr>Google Cloud Vertex PaLM settings\n",
        "\n",
        "#@markdown Enter the Google Cloud Project ID where the Vertex API is enabled:\n",
        "GCP_VERTEX_PROJECT_ID = \"gcp-project-id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the Google Cloud Project location where the Vertex API is configured to run:\n",
        "GCP_VERTEX_LOCATION = \"gcp-project-location-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the desired Vertex model name to use (refer to the guide provided [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) for an overview of available model names and types).\n",
        "#@markdown <br>If you have opted to [fine-tune](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) a model with your own data, enter the `model_resource_name` value (`projects/<project_number>/locations/<region>/models/<model_id>`) instead:\n",
        "VERTEX_MODEL_NAME = \"google/text-bison@001\" #@param {type:\"string\"}\n",
        "IS_FINE_TUNED_MODEL = VERTEX_MODEL_NAME.startswith('projects/')\n",
        "\n",
        "#@markdown <hr>Title optimisation settings\n",
        "\n",
        "#@markdown Input the additional features you would like to use in the prompt for generating titles, beyond what is already defined in `FEED_ITEM_MAIN_FEATURES`:\n",
        "TITLE_PROMPT_FEATURES = \"Description\" #@param {type:\"string\"}\n",
        "TITLE_PROMPT_FEATURES = convert_comma_seperated_str_to_list(TITLE_PROMPT_FEATURES)\n",
        "TITLE_PROMPT_FEATURES = FEED_ITEM_MAIN_FEATURES + [\n",
        "    feature for feature in TITLE_PROMPT_FEATURES\n",
        "    if feature and feature not in FEED_ITEM_MAIN_FEATURES]\n",
        "\n",
        "#@markdown Choose the desired prompt type:\n",
        "TITLE_PROMPT_TYPE = \"FEW_SHOT\" #@param [\"ZERO_SHOT\", \"FEW_SHOT\"]\n",
        "IS_TITLE_PROMPT_FEW_SHOT = TITLE_PROMPT_TYPE == 'FEW_SHOT'\n",
        "DEFAULT_MAX_FEW_SHOT_PROMPT_ITEMS = 5\n",
        "\n",
        "#@markdown **For Few-Shot prompting**: Enter the best *n* (e.g. 5, max 10) `FEED_ITEM_ID` samples from your input.\n",
        "#@markdown These samples will be used for prompt-tuning to teach the LLM to generate similar titles.\n",
        "#@markdown <br>Leave empty to have FeedGen automatically select the top 5 high-quality items for you:\n",
        "TITLE_FEW_SHOT_TOP_ITEM_IDS = \"\" #@param {type:\"string\"}\n",
        "TITLE_FEW_SHOT_TOP_ITEM_IDS = convert_comma_seperated_str_to_list(TITLE_FEW_SHOT_TOP_ITEM_IDS)\n",
        "\n",
        "#@markdown Refer to this [guide](https://cloud.google.com/vertex-ai/docs/generative-ai/text/test-text-prompts) for more information on these parameters:\n",
        "TITLE_TEMPERATURE = 0.2 #@param {type:\"number\"}\n",
        "TITLE_MAX_OUTPUT_TOKENS = 40 #@param {type:\"integer\"}\n",
        "TITLE_TOP_K = 1 #@param {type:\"integer\"}\n",
        "TITLE_TOP_P = 0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown <hr>Description generation settings\n",
        "\n",
        "#@markdown Input the additional features you would like to use in the prompt for generating descriptions, beyond what is already defined in `FEED_ITEM_MAIN_FEATURES`:\n",
        "DESCRIPTION_PROMPT_FEATURES = \"Title, Highlights\" #@param {type:\"string\"}\n",
        "DESCRIPTION_PROMPT_FEATURES = convert_comma_seperated_str_to_list(DESCRIPTION_PROMPT_FEATURES)\n",
        "DESCRIPTION_PROMPT_FEATURES = FEED_ITEM_MAIN_FEATURES + [\n",
        "    feature for feature in DESCRIPTION_PROMPT_FEATURES\n",
        "    if feature and feature not in FEED_ITEM_MAIN_FEATURES]\n",
        "\n",
        "#@markdown Choose the desired prompt type:\n",
        "DESCRIPTION_PROMPT_TYPE = \"ZERO_SHOT\" #@param [\"ZERO_SHOT\", \"FEW_SHOT\"]\n",
        "IS_DESCRIPTION_PROMPT_FEW_SHOT = DESCRIPTION_PROMPT_TYPE == 'FEW_SHOT'\n",
        "\n",
        "#@markdown **For Few-Shot prompting**: Enter the best *n* (e.g. 5, max 10) `FEED_ITEM_ID` samples from your input.\n",
        "#@markdown These samples will be used for prompt-tuning to teach the LLM to generate similar descriptions.\n",
        "#@markdown <br>Leave empty to have FeedGen automatically select the top 5 high-quality items for you:\n",
        "DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS = \"\" #@param {type:\"string\"}\n",
        "DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS = convert_comma_seperated_str_to_list(DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS)\n",
        "\n",
        "#@markdown Refer to this [guide](https://cloud.google.com/vertex-ai/docs/generative-ai/text/test-text-prompts) for more information on these parameters:\n",
        "DESCRIPTION_TEMPERATURE = 0.2 #@param {type:\"number\"}\n",
        "DESCRIPTION_MAX_OUTPUT_TOKENS = 256 #@param {type:\"integer\"}\n",
        "DESCRIPTION_TOP_K = 40 #@param {type:\"integer\"}\n",
        "DESCRIPTION_TOP_P = 0.8 #@param {type:\"number\"}\n",
        "\n",
        "# Validation rules\n",
        "if not GCP_VERTEX_PROJECT_ID or not GCP_VERTEX_LOCATION or not VERTEX_MODEL_NAME:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"GCP_VERTEX_PROJECT_ID\" AND \"GCP_VERTEX_LOCATION\" AND \"VERTEX_MODEL_NAME\" '\n",
        "      'are provided.')\n",
        "if IS_TITLE_PROMPT_FEW_SHOT and len(TITLE_FEW_SHOT_TOP_ITEM_IDS) > 10:\n",
        "  raise ValueError(\n",
        "    'Invalid input! Too many \"TITLE_FEW_SHOT_TOP_ITEM_IDS\" were provided. '\n",
        "    'Please include a maximum of 10 items to avoid running into API token limits.')\n",
        "if IS_DESCRIPTION_PROMPT_FEW_SHOT and len(DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS) > 10:\n",
        "  raise ValueError(\n",
        "    'Invalid input! Too many \"DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS\" were provided. '\n",
        "    'Please include a maximum of 10 items to avoid running into API token limits.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a0QiM3Iz6B17"
      },
      "outputs": [],
      "source": [
        "#@title Intialize the model and configurable prompts\n",
        "from google.cloud import aiplatform\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "aiplatform.init(project=GCP_VERTEX_PROJECT_ID, location=GCP_VERTEX_LOCATION)\n",
        "\n",
        "if IS_FINE_TUNED_MODEL:\n",
        "  available_tuned_models = TextGenerationModel.list_tuned_model_names()\n",
        "  if VERTEX_MODEL_NAME in available_tuned_models:\n",
        "    model = TextGenerationModel.get_tuned_model(VERTEX_MODEL_NAME)\n",
        "  else:\n",
        "    raise ValueError(\n",
        "        f\"The provided model name: '{VERTEX_MODEL_NAME}' is not in the list of \"\n",
        "        f'available tuned models: {available_tuned_models}. Please enter a '\n",
        "        'valid model name or change the associated GCP project and/or location.'\n",
        "    )\n",
        "else:\n",
        "  model = TextGenerationModel.from_pretrained(VERTEX_MODEL_NAME)\n",
        "\n",
        "title_prompt = [\n",
        "    f'Generate a Google Shopping ad title in 15 words or less in {GENERATION_LANGUAGE} using the given product information.',\n",
        "    f'Include all of the following features in the generated title: \"{FEED_ITEM_MAIN_FEATURES}\".',\n",
        "    'Product information:',\n",
        "]\n",
        "title_prompt.extend(f'{column_name}: \"{{{column_name}}}\".' for column_name in TITLE_PROMPT_FEATURES)\n",
        "title_prompt = '\\n'.join(title_prompt)\n",
        "\n",
        "title_prompt_few_shot = (\n",
        "  f'{title_prompt}\\n'\n",
        "  f'The generated title is: {{{FEED_ITEM_TITLE}}}'\n",
        ")\n",
        "title_gen_model_params = {\n",
        "  'temperature': TITLE_TEMPERATURE,\n",
        "  'max_output_tokens': TITLE_MAX_OUTPUT_TOKENS,\n",
        "  'top_k': TITLE_TOP_K,\n",
        "  'top_p': TITLE_TOP_P,\n",
        "}\n",
        "\n",
        "description_prompt = [\n",
        "    f'Generate a detailed description in {GENERATION_LANGUAGE} for a product that has the following information:',\n",
        "]\n",
        "description_prompt.extend(f'{column_name}: \"{{{column_name}}}\".' for column_name in DESCRIPTION_PROMPT_FEATURES)\n",
        "description_prompt = '\\n'.join(description_prompt)\n",
        "\n",
        "description_prompt_few_shot = (\n",
        "  f'{description_prompt}\\n'\n",
        "  f'The generated description is: {{{FEED_ITEM_DESCRIPTION}}}'\n",
        ")\n",
        "description_gen_model_params = {\n",
        "  'temperature': DESCRIPTION_TEMPERATURE,\n",
        "  'max_output_tokens': DESCRIPTION_MAX_OUTPUT_TOKENS,\n",
        "  'top_k': DESCRIPTION_TOP_K,\n",
        "  'top_p': DESCRIPTION_TOP_P,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1BDxftHNtfF-"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "import re\n",
        "from typing import Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_text # do not remove unused import as it's required in runtime\n",
        "\n",
        "\n",
        "def generate_prompt(\n",
        "    base_prompt: str,\n",
        "    item_row: pd.Series,\n",
        ") -> str:\n",
        "  generated_prompt = base_prompt\n",
        "  for key in item_row.keys().to_list():\n",
        "    generated_prompt = generated_prompt.replace(\n",
        "      f'{{{key}}}', str(item_row[key]))\n",
        "  generated_prompt = re.sub(r'\\{.*?\\}', '', generated_prompt)\n",
        "  return generated_prompt\n",
        "\n",
        "def generate_few_shot_prompt(\n",
        "    base_prompt: str,\n",
        "    item_row: pd.Series,\n",
        "    few_shot_item_rows: pd.DataFrame,\n",
        ") -> str:\n",
        "  prompt_few_shot = []\n",
        "  for _, few_shot_item_row in few_shot_item_rows.iterrows():\n",
        "    prompt_few_shot.append(generate_prompt(base_prompt, few_shot_item_row))\n",
        "  prompt_few_shot.append(generate_prompt(base_prompt, item_row))\n",
        "  return '\\n\\n'.join(prompt_few_shot)\n",
        "\n",
        "def generate_text(\n",
        "    base_prompt: str,\n",
        "    item_row: pd.Series,\n",
        "    few_shot_item_rows: Optional[pd.DataFrame],\n",
        "    model_generation_params: Mapping[str, str],\n",
        ") -> str:\n",
        "\n",
        "  # Generate prompt from item\n",
        "  if few_shot_item_rows is not None and not few_shot_item_rows.empty:\n",
        "    prompt = generate_few_shot_prompt(base_prompt, item_row, few_shot_item_rows)\n",
        "  else:\n",
        "    prompt = generate_prompt(base_prompt, item_row)\n",
        "\n",
        "  logging.debug('Prompt: [%s]\\nModel params: [%r]', prompt, model_generation_params)\n",
        "  response = model.predict(prompt, **model_generation_params)\n",
        "  logging.debug('Response: [%s]', response.text)\n",
        "\n",
        "  return response.text\n",
        "\n",
        "def generate_and_evaluate_text(\n",
        "    base_prompt: str,\n",
        "    item_row: pd.Series,\n",
        "    item_key: str,\n",
        "    few_shot_item_rows: Optional[pd.DataFrame],\n",
        "    model_generation_params: Mapping[str, str],\n",
        "    main_features: Sequence[str] = FEED_ITEM_MAIN_FEATURES,\n",
        "    regeneration_max_retries: int = 3,\n",
        "    regeneration_temperature_step: float = 0.2,\n",
        "    regeneration_top_k_step: int = 10,\n",
        "    regeneration_top_p_step: float = 0.2,\n",
        ") -> Tuple[str, str, str, str]:\n",
        "  reduced_item_row = item_row.drop(labels=[item_key])\n",
        "  min_missing_features_count = None\n",
        "  generated_variants = {}\n",
        "  output_dict = {}\n",
        "\n",
        "  for i in range(0, regeneration_max_retries + 1):\n",
        "    generation_params = model_generation_params.copy()\n",
        "    if i >= 1:\n",
        "      if item_key == FEED_ITEM_DESCRIPTION:\n",
        "        generation_params['temperature'] += (i * regeneration_temperature_step)\n",
        "      else:\n",
        "        generation_params['top_k'] += (i * regeneration_top_k_step)\n",
        "        generation_params['top_p'] += (i * regeneration_top_p_step)\n",
        "    generated_text = generate_text(base_prompt, reduced_item_row, few_shot_item_rows, generation_params)\n",
        "    if generated_text:\n",
        "      missing_features, features_cosine_similarity = get_missing_features_in_text(item_row, generated_text, main_features)\n",
        "    else:\n",
        "      missing_features = ', '.join(main_features)\n",
        "      features_cosine_similarity = ', '.join(['0.00' for _ in range(len(main_features))])\n",
        "    missing_features, features_cosine_similarity = get_missing_features_in_text(item_row, generated_text, main_features)\n",
        "    missing_features_list = list(filter(bool, missing_features.split(', ')))\n",
        "\n",
        "    generated_variants[f'VARIANT_{i+1}'] = {\n",
        "        'generated_text': generated_text,\n",
        "        'missing_features': missing_features,\n",
        "        'missing_features_similarity': features_cosine_similarity,\n",
        "        'model_params': str(generation_params),\n",
        "    }\n",
        "    if not min_missing_features_count or len(missing_features_list) < min_missing_features_count:\n",
        "      min_missing_features_count = len(missing_features_list)\n",
        "      output_dict = generated_variants[f'VARIANT_{i+1}']\n",
        "    if min_missing_features_count == 0:\n",
        "      break\n",
        "\n",
        "  needs_approval = len(output_dict['missing_features']) > 0\n",
        "\n",
        "  return (\n",
        "      output_dict['generated_text'],\n",
        "      output_dict['missing_features'],\n",
        "      output_dict['missing_features_similarity'],\n",
        "      output_dict['model_params'],\n",
        "      str(generated_variants),\n",
        "      FEED_OUTPUT_STATUS_NEEDS_APROVAL if needs_approval else FEED_OUTPUT_STATUS_PRE_APPROVED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jwcc_RVFy18e"
      },
      "outputs": [],
      "source": [
        "#@title Perform inference for titles and descriptions\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "max_few_shot_items = min(DEFAULT_MAX_FEW_SHOT_PROMPT_ITEMS, len(input_feed_data))\n",
        "best_quality_items = input_feed_data.iloc[-max_few_shot_items:][FEED_ITEM_ID].to_list()\n",
        "\n",
        "if IS_TITLE_PROMPT_FEW_SHOT and not TITLE_FEW_SHOT_TOP_ITEM_IDS:\n",
        "  TITLE_FEW_SHOT_TOP_ITEM_IDS = best_quality_items\n",
        "if IS_DESCRIPTION_PROMPT_FEW_SHOT and not DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS:\n",
        "  DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS = best_quality_items\n",
        "\n",
        "title_few_shot_products = (\n",
        "    None if not IS_TITLE_PROMPT_FEW_SHOT or not TITLE_FEW_SHOT_TOP_ITEM_IDS\n",
        "    else input_feed_data[input_feed_data[FEED_ITEM_ID].isin(TITLE_FEW_SHOT_TOP_ITEM_IDS)]\n",
        ")\n",
        "description_few_shot_products = (\n",
        "    None if not IS_DESCRIPTION_PROMPT_FEW_SHOT or not DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS\n",
        "    else input_feed_data[input_feed_data[FEED_ITEM_ID].isin(DESCRIPTION_FEW_SHOT_TOP_ITEM_IDS)]\n",
        ")\n",
        "\n",
        "logging.info('Generating titles for the given input...')\n",
        "input_feed_data[[\n",
        "    FEED_OUTPUT_GENERATED_TITLE,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_TITLE,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_MODEL_PARAMS,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_VARIANTS,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_STATUS]] = input_feed_data.progress_apply(\n",
        "        lambda row: generate_and_evaluate_text(\n",
        "            base_prompt=title_prompt_few_shot if IS_TITLE_PROMPT_FEW_SHOT else title_prompt,\n",
        "            item_row=row,\n",
        "            item_key=FEED_ITEM_TITLE,\n",
        "            few_shot_item_rows=title_few_shot_products,\n",
        "            model_generation_params=title_gen_model_params),\n",
        "        axis='columns',\n",
        "        result_type='expand')\n",
        "\n",
        "logging.info('Generating descriptions for the given input...')\n",
        "input_feed_data[[\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_DESCRIPTION,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_MODEL_PARAMS,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_VARIANTS,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_STATUS]] = input_feed_data.progress_apply(\n",
        "        lambda row: generate_and_evaluate_text(\n",
        "            base_prompt=description_prompt_few_shot if IS_DESCRIPTION_PROMPT_FEW_SHOT else description_prompt,\n",
        "            item_row=row,\n",
        "            item_key=FEED_ITEM_DESCRIPTION,\n",
        "            few_shot_item_rows=description_few_shot_products,\n",
        "            model_generation_params=description_gen_model_params),\n",
        "        axis='columns',\n",
        "        result_type='expand')\n",
        "\n",
        "input_feed_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aZeBuOUqCL5"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J56PU4nFujX"
      },
      "source": [
        "Make a copy of the following [template](https://docs.google.com/spreadsheets/d/1Ro91GhHaurph5zaqgr4n1PDqFZwuln-jpwam3irYq5k/edit#gid=1221408551) Google Sheets spreadsheet, then paste the ID and run the cells below to output the generated data. Read the instructions in the **Getting Started** worksheet to familiarise yourself with how to use the sheet, particularly how it can be used to set up a supplemental feed in Merchant Center."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8eBM6TdWGa02"
      },
      "outputs": [],
      "source": [
        "#@title Configurable parameters { run: 'auto' }\n",
        "\n",
        "#@markdown Enter the output spreadsheet ID:\n",
        "OUTPUT_SPREADSHEET_ID = \"template-sheet-id-goes-here\" #@param {type:\"string\"}\n",
        "OUTPUT_GENERATED_WORKSHEET_NAME = 'Generated'\n",
        "OUTPUT_SUMMARY_WORKSHEET_NAME = 'Summary'\n",
        "\n",
        "# Validation rules\n",
        "if not OUTPUT_SPREADSHEET_ID:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure \"OUTPUT_SPREADSHEET_ID\" is provided.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GGoycoROru7j"
      },
      "outputs": [],
      "source": [
        "#@title Write the generated data to the output Google Sheets spreadsheet\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "sheets_client = gspread.authorize(creds)\n",
        "output_spreadsheet = sheets_client.open_by_key(OUTPUT_SPREADSHEET_ID)\n",
        "\n",
        "fixed_order_columns = [\n",
        "    FEED_OUTPUT_ITEM_ID,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_STATUS,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_STATUS,\n",
        "    FEED_OUTPUT_TITLE,\n",
        "    FEED_OUTPUT_GENERATED_TITLE,\n",
        "    FEED_OUTPUT_DESCRIPTION,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION,\n",
        "\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_TITLE,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_TITLE_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_TITLE,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_MODEL_PARAMS,\n",
        "    FEED_OUTPUT_GENERATED_TITLE_VARIANTS,\n",
        "\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_DESCRIPTION,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_DESCRIPTION_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_MISSING_FEATURES_IN_GENERATED_DESCRIPTION,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_SIMILARITY_SCORE,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_MODEL_PARAMS,\n",
        "    FEED_OUTPUT_GENERATED_DESCRIPTION_VARIANTS,\n",
        "]\n",
        "input_feed_data.rename(columns={\n",
        "    f'{FEED_ITEM_ID}': FEED_OUTPUT_ITEM_ID,\n",
        "    f'{FEED_ITEM_TITLE}': FEED_OUTPUT_TITLE,\n",
        "    f'{FEED_ITEM_DESCRIPTION}': FEED_OUTPUT_DESCRIPTION}, inplace=True)\n",
        "output_feed_data = input_feed_data[\n",
        "    fixed_order_columns +\n",
        "    [col for col in input_feed_data if col not in fixed_order_columns]\n",
        "]\n",
        "output_feed_data.sort_values(\n",
        "    by=[FEED_OUTPUT_GENERATED_TITLE_STATUS,\n",
        "        FEED_OUTPUT_GENERATED_DESCRIPTION_STATUS], inplace=True)\n",
        "\n",
        "try:\n",
        "  output_sheet = output_spreadsheet.worksheet(OUTPUT_GENERATED_WORKSHEET_NAME)\n",
        "  output_sheet.clear()\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "  output_sheet = output_spreadsheet.add_worksheet(\n",
        "      OUTPUT_GENERATED_WORKSHEET_NAME,\n",
        "      rows=len(output_feed_data),\n",
        "      cols=len(output_feed_data.columns))\n",
        "\n",
        "set_with_dataframe(\n",
        "      output_sheet, output_feed_data, include_column_header=True)\n",
        "\n",
        "try:\n",
        "  summary_sheet = output_spreadsheet.worksheet(OUTPUT_SUMMARY_WORKSHEET_NAME)\n",
        "  summary_sheet.clear()\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "  summary_sheet = output_spreadsheet.add_worksheet(\n",
        "      OUTPUT_SUMMARY_WORKSHEET_NAME,\n",
        "      rows=len(input_feed_summary),\n",
        "      cols=len(input_feed_summary.columns))\n",
        "\n",
        "set_with_dataframe(\n",
        "      summary_sheet, input_feed_summary, include_column_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QghJ6segSZ9-"
      },
      "source": [
        "### How was the sample data generated?\n",
        "\n",
        "All data in the template Google Sheets spreadsheet was generated using the `Faker` library as shown by the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F_7SxEXmSa78"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x8oKHhEkSePk"
      },
      "outputs": [],
      "source": [
        "#@title Generate sample data with Faker\n",
        "#@markdown The generated data format resembles that of a typical Google Merchant Center Shopping feed.\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "\n",
        "SIZES = ['XS', 'S', 'M', 'L', 'XL']\n",
        "DESCRIPTION_MAX_LENGTHS = [400, 700, 1000]\n",
        "\n",
        "fake = Faker(['en'])\n",
        "rows = [['Item ID', 'Title', 'Description', 'Brand', 'Size', 'Color', 'Clicks']]\n",
        "\n",
        "for i in range (1, 501):\n",
        "  random_brand = fake.company()\n",
        "  random_size = fake.random_element(elements=SIZES)\n",
        "  random_color = fake.safe_color_name()\n",
        "  random_description_max_length = fake.random_element(\n",
        "      elements=DESCRIPTION_MAX_LENGTHS)\n",
        "  title = ', '.join([\n",
        "       '' if i % 3 == 0 else random_brand,\n",
        "       fake.catch_phrase(),\n",
        "       '' if i % 4 == 0 else random_size,\n",
        "       '' if i % 5 == 0 else random_color,\n",
        "  ])\n",
        "  description = ', '.join([\n",
        "      '' if i % 6 == 0 else random_brand,\n",
        "      fake.text(max_nb_chars=random_description_max_length),\n",
        "  ])\n",
        "  row = [\n",
        "      i,\n",
        "      title,\n",
        "      title if i % 7 == 0 else description,\n",
        "      random_brand,\n",
        "      random_size,\n",
        "      random_color,\n",
        "      random.randint(1, 10000),\n",
        "  ]\n",
        "  rows.append(row)\n",
        "\n",
        "generated_feed = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "generated_feed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-NjqBt4sSj7K"
      },
      "outputs": [],
      "source": [
        "#@title Output to csv\n",
        "#@markdown The file will be saved in the default 'home' folder on Colab (`/content/`) and can be downloaded from there.\n",
        "generated_feed.to_csv('/content/faker_sample.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SF1rUy2hqp8A",
        "37CfxrLUjxiQ",
        "QghJ6segSZ9-"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
